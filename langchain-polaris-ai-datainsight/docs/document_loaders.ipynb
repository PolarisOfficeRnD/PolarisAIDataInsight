{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "sidebar_label: PolarisAIDataInsight\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PolarisAIDataInsightLoader\n",
    "\n",
    "- TODO: Make sure API reference link is correct.\n",
    "\n",
    "This notebook provides a quick overview for getting started with PolarisAIDataInsight [Document Loader](###TODO). For detailed documentation of all PolarisAIDataInsightLoader features and configurations head to the [API reference](###TODO).\n",
    "\n",
    "## Overview\n",
    "### Integration details\n",
    "\n",
    "- TODO: Fill in table features.\n",
    "- TODO: Remove JS support link if not relevant, otherwise ensure link is correct.\n",
    "- TODO: Make sure API reference links are correct.\n",
    "\n",
    "| Class | Package | Local | Serializable | [JS support](###TODO)|\n",
    "| :--- | :--- | :---: | :---: |  :---: |\n",
    "| [PolarisAIDataInsightLoader](###TODO) | [langchain-polaris-ai-datainsight](https://pypi.org/project/langchain-polaris-ai-datainsight/) | ❌ | ❌ | ✅ | \n",
    "### Loader features\n",
    "| Source | Document Lazy Loading | Native Async Support\n",
    "| :---: | :---: | :---: | \n",
    "| PolarisAIDataInsightLoader | ✅ | ❌ | \n",
    "\n",
    "## Setup\n",
    "\n",
    "To access PolarisAIDataInsight document loader you'll need to install the `langchain-polaris-ai-datainsight` integration package, and create a **Polaris AI DataInsight** account and get an API key.\n",
    "\n",
    "### Credentials\n",
    "\n",
    "Head to [here](https://datainsight.polarisoffice.com/api/keys) to sign up to PolarisAIDataInsight and generate an API key. Once you've done this set the POLARIS_AI_DATA_INSIGHT_API_KEY environment variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"POLARIS_AI_DATA_INSIGHT_API_KEY\"] = getpass.getpass(\"Enter your PolarisAIDataInsight API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "Install **langchain-polaris-ai-datainsight**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-polaris-ai-datainsight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "Now we can instantiate our model object and load documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_polaris_ai_datainsight import PolarisAIDataInsightLoader\n",
    "\n",
    "loader = PolarisAIDataInsightLoader(\n",
    "    file_path=\"/path/to/file\",\n",
    "    mode=\"page\"     # \"element\", \"page\", or \"single\". (default is \"single\") \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lazy Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = []\n",
    "for doc in loader.lazy_load():\n",
    "    page.append(doc)\n",
    "\n",
    "print(page[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use with Vector Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a query and file for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain[openai]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process :\n",
    "\n",
    "1. Set an environment variable with your OpenAI API key (or the key for any other embedding model you plan to use).  \n",
    "2. Load the document and extract its contents with loader.  \n",
    "3. Split the extracted text and store the chunks in a vector database.  \n",
    "4. Retrieve relevant chunks from the vector store and pass them to the LLM to generate a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query = \"What is the meaning of MIT License?\"\n",
    "test_file = \"./example/example.docx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_polaris_ai_datainsight import PolarisAIDataInsightLoader\n",
    "\n",
    "loader = PolarisAIDataInsightLoader(\n",
    "    file_path=\"./example/example.docx\"\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    ")\n",
    "texts = text_splitter.split_documents(docs)\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "vector_store = InMemoryVectorStore.from_documents(\n",
    "    texts,\n",
    "    embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = vector_store.similarity_search(test_query)\n",
    "retrieved_docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to get resources information(e.g. image path) easily, use this method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_polaris_ai_datainsight import PolarisAIDataInsightLoader\n",
    "\n",
    "resources_metadata = PolarisAIDataInsightLoader.get_resources_from_documents(retrieved_docs)\n",
    "resources_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Example Prompt template \n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "\"\"\"\n",
    "{query}\n",
    "\n",
    "Please compose your answer based on the information provided below.\n",
    "For any images, charts, or tables cited in References, consult the details found in Resources.\n",
    "\n",
    "** References **\n",
    "{context}\n",
    "\n",
    "\n",
    "** Resources **\n",
    "{resources_metadata}\n",
    "\"\"\"]\n",
    ")\n",
    "answer = prompt.invoke({\n",
    "    \"question\": test_query,\n",
    "    \"context\": \"\\n\\n-------------\\n\\n\".join([doc.page_content for doc in retrieved_docs]),\n",
    "    \"resources_metadata\": resources_metadata\n",
    "})\n",
    "answer.messages[0].content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
